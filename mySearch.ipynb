{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Simple Search Engine - Advance Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing some important libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "MINIMUM_CHR = 2\n",
    "MAP_PATH = \"file_link_map.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Tries data structure as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class for the set of index terms, where each external node stores the index of the occurrence list of the associated term.\n",
    "\n",
    "class myNode():\n",
    "    \n",
    "    myChld = {}\n",
    "    \n",
    "    # Reference for the occurrence lists\n",
    "    \n",
    "    myReferences = None\n",
    "    \n",
    "    myNum = 0\n",
    "    \n",
    "    myK = None\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.myChld = {}\n",
    "\n",
    "class myTries(object):\n",
    "    \n",
    "    myRt = myNode()\n",
    "    \n",
    "    # Adding a node\n",
    "    def add(self, w, myReferences):\n",
    "        \n",
    "        myC = self.myRt\n",
    "        \n",
    "        if len(w)==0:\n",
    "            return\n",
    "        \n",
    "        for i,c in enumerate(w):\n",
    "            \n",
    "            if c in myC.myChld:\n",
    "                myC = myC.myChld[c]\n",
    "            \n",
    "            else:\n",
    "                nNode = myNode()\n",
    "                \n",
    "                nNode.myK = c\n",
    "                \n",
    "                myC.myChld[c] = nNode\n",
    "                \n",
    "                myC = myC.myChld[c]\n",
    "        \n",
    "        \n",
    "        if myC.myReferences == None:\n",
    "            myC.myReferences = myReferences\n",
    "        \n",
    "        return \n",
    "                    \n",
    "    # This is for getting reference by giving word     \n",
    "    def get(self, w):\n",
    "        \n",
    "        myC = self.myRt\n",
    "        \n",
    "        if len(w)==0:\n",
    "            return None\n",
    "        \n",
    "        for i,c in enumerate(w):\n",
    "            if c in myC.myChld:\n",
    "                myC = myC.myChld[c]\n",
    "                if i == len(w)-1:\n",
    "                    myC.myNum = myC.myNum + 1\n",
    "                    print (myC.myReferences)\n",
    "                    return myC.myReferences\n",
    "            # no matching word\n",
    "            else:\n",
    "                return 0\n",
    "           \n",
    "        return 0    \n",
    "    \n",
    "    # Get recommendation by giving string\n",
    "    \n",
    "    def getKeys(self, myStr):\n",
    "        myC = self.myRt\n",
    "        \n",
    "        for i,c in enumerate(myC.myChld):\n",
    "            if c in myC.myChld:\n",
    "                myC = myC.myChld[c]\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        s_kList = self.myDf(myC)\n",
    "        \n",
    "        kList = []\n",
    "            \n",
    "        \n",
    "        for i,w in enumerate(s_kList):\n",
    "            z = myStr[:-1] + w\n",
    "            kList.append(z)\n",
    "        \n",
    "        return kList\n",
    "        \n",
    "    # Using DF to get children nodes\n",
    "    def myDf(self, myRt):\n",
    "        \n",
    "        if myRt.myK:\n",
    "            c_Let = myRt.myK\n",
    "        \n",
    "        else: \n",
    "            c_Let = ''\n",
    "        \n",
    "        kList = []\n",
    "        \n",
    "        if myRt.myChld:\n",
    "            for tNode in myRt.myChld:\n",
    "                s_kList = self.myDf(myRt.myChld[tNode])\n",
    "                if len(s_kList)==0:\n",
    "                    kList.append(c_Let)\n",
    "                else:\n",
    "                    #print (s_kList)\n",
    "                    for i,w in enumerate(s_kList):\n",
    "                        z = c_Let + w\n",
    "                        kList.append(z)\n",
    "        \n",
    "        else:\n",
    "            return [c_Let]\n",
    "            \n",
    "        \n",
    "        return kList "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This class is for storing core information stored by the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This implements a dictionary having words and lists that refer to those words\n",
    "\n",
    "class myInvertedIndx(object):\n",
    "    \n",
    "    myt = myTries()\n",
    "    \n",
    "    myOcc_Lists = []\n",
    "    \n",
    "    # Get reference to the collection using the word\n",
    "    def getRef(self, key):\n",
    "        \n",
    "        myRef = self.myt.get(key)\n",
    "        \n",
    "        #myRef = 1 # ???\n",
    "        \n",
    "        if myRef != None and myRef < len(self.myOcc_Lists):\n",
    "            return self.myOcc_Lists[myRef]\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Insert collection of words with reference to the page.\n",
    "    def insertCollection(self, key, value):\n",
    "        \n",
    "        myOcc_Collect = self.getRef(key)\n",
    "        \n",
    "        if(myOcc_Collect == None):\n",
    "            \n",
    "            self.myOcc_Lists.append({\"key\": key, value: 1})\n",
    "            \n",
    "            myRef = len(self.myOcc_Lists)-1\n",
    "            \n",
    "            self.myt.add(key, myRef)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if value in myOcc_Collect:\n",
    "                myOcc_Collect[value] = myOcc_Collect[value]+1\n",
    "            \n",
    "            else:\n",
    "                myOcc_Collect[value] = 1\n",
    "        \n",
    "        \n",
    "        return \n",
    "    \n",
    "    # Get the keys\n",
    "    def getRKeys(self, myStr):\n",
    "        return self.myt.getKeys(myStr)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This class is for building tries using the given inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the tries data structure by using information from the input pages.\n",
    "\n",
    "class mySearch(object):\n",
    "    \n",
    "    inv_Index = myInvertedIndx()\n",
    "\n",
    "    def buildTries(self):\n",
    "        \n",
    "        f = open(MAP_PATH, \"r\") \n",
    "        \n",
    "        file_link_map = json.loads(f.readlines()[0]) \n",
    "\n",
    "        mystpWords = set(stopwords.words('english'))\n",
    "        \n",
    "        mystpWords.update(string.punctuation)\n",
    "\n",
    "        for filename in file_link_map:\n",
    "            \n",
    "            f = open(filename, encoding=\"utf8\")\n",
    "            \n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "            \n",
    "            [script.extract() for script in soup.findAll('script')]\n",
    "            \n",
    "            [style.extract() for style in soup.findAll('style')]\n",
    "            \n",
    "            words = word_tokenize(soup.get_text())\n",
    "            \n",
    "            words = [i for i in words if all(j not in string.punctuation for j in i)]\n",
    "            \n",
    "            for word in words:\n",
    "                if word.lower() not in mystpWords and len(word) > MINIMUM_CHR and word.isdigit()==False:\n",
    "                    \n",
    "                        try:\n",
    "                            word = word.lower().strip().encode('ascII')\n",
    "                            \n",
    "                        except:\n",
    "                            a = 1\n",
    "                            \n",
    "                else:\n",
    "                    self.inv_Index.insertCollection(word, file_link_map[filename])\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    def search(self, key):\n",
    "        \n",
    "        if self.inv_Index.getRef(key) == None:\n",
    "            \n",
    "            print('a')\n",
    "            \n",
    "            return {}\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return self.inv_Index.getRef(key)\n",
    "    \n",
    "    def getRecomendKey(self, myStr):\n",
    "        \n",
    "        return self.inv_Index.getKeys(myStr) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = mySearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "se.buildTries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to sort the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_value(d):\n",
    "    \n",
    "    items=d.items()\n",
    "    \n",
    "    \n",
    "    backitems=[[v[1],v[0]] for v in items]\n",
    "    \n",
    "    backitems.sort(reverse=True)\n",
    "    \n",
    "    return [ backitems[i][1] for i in range(0,len(backitems))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output pages with respect to the given keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.gamasutra.com/view/news/307008/DeepMind_wants_to_answer_the_big_ethical_questions_posed_by_AI': 280, 'http://www.gamasutra.com/category/programming/': 418, 'http://www.gamasutra.com/blogs/BenWeber/20160314/267956/DeepMind_Challenges_for_StarCraft.php': 719, 'https://www.gamasutra.com/view/news/284951/DeepMind_and_Blizzard_team_up_to_release_API_aimed_at_AI_enhancement.php': 282, 'http://www.gamasutra.com/view/news/331151/For_Lucas_Pope_Return_of_the_Obra_Dinn_was_a_bunch_of_appealing_design_problems.php': 1572, 'https://www.gdconf.com/': 62, 'http://www.gamasutra.com/view/news/237515/New_DeepMind_AI_learns_to_play_Atari_2600_games_at_human_levels.php': 239, 'http://www.gamasutra.com/view/news/331710/Unity_offers_guidelines_for_what_it_considers_ethical_AI_design.php': 334, 'https://deepmind.com/': 210, 'https://deepmind.com/blog/deepmind-and-blizzard-release-starcraft-ii-ai-research-environment/': 466}\n",
      "https://www.gamasutra.com/view/news/307008/DeepMind_wants_to_answer_the_big_ethical_questions_posed_by_AI\n",
      "http://www.gamasutra.com/view/news/331710/Unity_offers_guidelines_for_what_it_considers_ethical_AI_design.php\n",
      "https://www.gdconf.com/\n",
      "http://www.gamasutra.com/category/programming/\n",
      "https://www.gamasutra.com/view/news/284951/DeepMind_and_Blizzard_team_up_to_release_API_aimed_at_AI_enhancement.php\n",
      "http://www.gamasutra.com/view/news/237515/New_DeepMind_AI_learns_to_play_Atari_2600_games_at_human_levels.php\n",
      "https://deepmind.com/\n",
      "https://deepmind.com/blog/deepmind-and-blizzard-release-starcraft-ii-ai-research-environment/\n",
      "http://www.gamasutra.com/view/news/331151/For_Lucas_Pope_Return_of_the_Obra_Dinn_was_a_bunch_of_appealing_design_problems.php\n",
      "http://www.gamasutra.com/blogs/BenWeber/20160314/267956/DeepMind_Challenges_for_StarCraft.php\n"
     ]
    }
   ],
   "source": [
    "rank = None\n",
    "\n",
    "keywords = [\"DeepMind\"]\n",
    "\n",
    "keylist = []\n",
    "\n",
    "odict = {}\n",
    "\n",
    "for key in keywords:\n",
    "    \n",
    "    result = se.search(key)\n",
    "    \n",
    "    print (result)\n",
    "    \n",
    "    if result:\n",
    "        \n",
    "        result.pop('key', None)\n",
    "        \n",
    "        keylist.append(result.keys())\n",
    "        \n",
    "        for r in result:\n",
    "            \n",
    "            if r in odict:\n",
    "                \n",
    "                odict[r] = odict[r] + result[r]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                odict[r] = result[r]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        keylist.append(result.keys())\n",
    "\n",
    "intersetion = None\n",
    "\n",
    "for kl in keylist:\n",
    "    \n",
    "    if intersetion == None:\n",
    "        \n",
    "        intersetion = set(kl)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        intersetion = set(intersetion) & set(kl)\n",
    "\n",
    "output = {}\n",
    "\n",
    "for sub_intersetion in intersetion:\n",
    "    \n",
    "    output[sub_intersetion] = odict[sub_intersetion]\n",
    "    \n",
    "    if output:\n",
    "        \n",
    "        rank = sort_by_value(output)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print ('No')\n",
    "    \n",
    "\n",
    "for page in output:\n",
    "    print (page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
